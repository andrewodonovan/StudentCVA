# My PDF manipulation library
import re

from bs4 import BeautifulSoup as bs
import slate3k as slate

# Get top resumÃ© words


# Load Job Description
import requests
from requests import get



find_job(self=None):

# TODO: Implement Linking
# https://ie.indeed.com/viewjob?jk=
# TODO: Show HTML links
# #======================================================================
#
#
# resume_keywords = []
#
# skill_file = open('keywords.txt', 'r')
# keywords = skill_file.readlines()
# skill_file.close()
#
# for kw in keywords:
#     resume_keywords.append(kw.upper().rstrip())
#
# # Resume sec3 loaded
#
# with open('cv-1.pdf', 'rb') as f:
#     doc = slate.PDF(f)
#
#     # Make new array
# doc_string = str(doc)
# lines = doc_string.splitlines()
# split = lines[0].split("\\n")
# split[0] = split[0].replace("['", "")
# clean_split = []
# section_split = []
# sanitised_split = []
#
# email = ""
# full_name = ""
# first_name = ""
# surname = ""
# address = ""
# phone_number = ""
#
# for s in split:
#     if (s != "") and (s != " ") and (s[0] != "\\"):
#         clean_split.append(s)
#         sanitised_split.append(s.upper().rstrip())
#
# for lin in clean_split:
#     # If the line is uppercase
#     if lin.isupper() and lin.find(":") != -1:
#         lin = ">" + lin
#     else:
#         pass
#
#     section_split.append(lin.rstrip())
#
# # TODO: Fix Employment table
#
#
# # HOLY GRAIL OF CODE - DO NOT REMOVE UNDER PENALTY OF EXECUTION!!!
#
#
# header_count = sum(1 for x in section_split if x.find(">") != -1)
#
# # Load Headings and Content
# content = []
# headings = []
#
# file = open("cv.txt", "w+")
#
# for s in section_split:
#     if s.find(">") == -1:
#         file.write(s + "\n")
#     else:
#         file.write("--BLANK_LINE_DO_NOT_READ--\n" + s + "\n")
# file.close()
#
# # ==========================================================
#     # https://ubuntuforums.org/showthread.php?t=1292871
# # ==========================================================
#
# # Original file to be split
# input_file = 'cv.txt'
#
# # Set the delimiting line for the splitter
# text_split_string = '--BLANK_LINE_DO_NOT_READ--'
#
# # Set the naming convention for the different sections
# file_name_format = 'section_#.txt'
#
#
# # Splitting function
# def text_splitter(fn):
#     # Apply the naming convention for the filename using the number passed into the function
#     filename = file_name_format.replace('#', str(fn))
#     # Write to the file and save the file to a variable
#     out = open(filename, 'w')
#     # Return the variable
#     return out
#
#
# # Open the master CV file
# file = open(input_file)
#
# # Read all lines of the file and save them to a list called lines
# lines = file.readlines()
#
# # File number counter
# file_number = 0
# # Save the output for the given file/section to the output file
# output = text_splitter(file_number)
#
# # Iterate through the lines..
# for line in lines:
#     # .. And if it hits the delimiting string ..
#     if text_split_string in line:
#         # .. Close the output ..
#         output.close()
#         # Increment the file number counter
#         file_number += 1
#         # Write what is written at this point to the text file
#         output = text_splitter(file_number)
#     else:
#         # Otherwise if we have not hit the delimiting string - continue writing
#         output.write(line)
#
# # Once all sections are read and split into files stop reading the file
# output.close()
#
# sections = [[]]
#
# # Dynamically create the 2D array
# for i in range(header_count):
#     sections.append([])
#
# # For the range of sections ...
# for i in range(0, header_count + 1):
#     # ... Load the dynamically generated files ...
#     filename = file_name_format.replace('#', str(i))
#     # ... Open the file ...
#     out = open(filename, 'r')
#     # ... load the section arrays ..
#     sections[i] = out.readlines()
#     # .. and stop reading from the file.
#     out.close()
#
# # For each section list in sections
# for sec in sections:
#     # For each section in the section lists
#     for s in sec:
#         # If the section string contains "SKILLS" ...
#         # if s.find("SKILLS") != -1:
#         # ... Print the section
#         # print(sec)
#         pass
#
# # TODO: Load in profile information
#
# filter(None, sections[0])
#
# # Set counter to keep track of the first line
# contact_counter = 1
# # Loop through the contact information section
# for s in sections[0]:
#     # If it is the first line..
#     if contact_counter == 1:
#         # Set the full name equal to the string
#         full_name = s
#         # Split the string at the first space
#         names = full_name.split(" ", 1)
#         # First Name is the first item of the names list
#         first_name = names[0]
#         # Surname is the second item on the names list
#         surname = names[1].rstrip()
#         # Increment the contact counter
#         contact_counter += 1
#     # Check for a phone number using RegEx (built my own with https://pythex.org/)
#     # and check against the string that is being iterrated through
#     phone_number_format = re.search("\(\+?\d*\)\d*.\d*.\d*", s)
#     # Check for an email address using RegEx (built my own with https://pythex.org/)
#     # and check against the string that is being iterrated through
#     email_format = re.search("[^@]+@[^@]+\.[^@]+", s)
#
#
#     if email_format:
#         email = email_format.group()
#
#     if phone_number_format:
#         phone_number = phone_number_format.group()
#
# # ===========================================================
# #                       SCRAPE JOB
# # ===========================================================
#
# print("\n ============================== \n Job Description \n ============================== \n")
#
# page = requests.get("https://ie.indeed.com/viewjob?jk=01852c1f9d40fd11&tk=1dsn3d00n99p4800&from=serp&vjs=3")
# soup = bs(page.content, 'html.parser')
# job_desc = soup
#
# # Remove footer li's
# soup.find('div', class_='jobsearch-Footer').decompose()
#
# job_posting_list_elems = soup.find_all('li')
#
# job_posting_keywords = []
# for element in job_posting_list_elems:
#     item = element
#     if item:
#         job_keyword = item.text.strip()
#         job_posting_keywords.append(job_keyword)
#
# # ===========================================================
# #                       COMPARE STRINGS
# # ===========================================================
# def compare_strings(keywords, sanitised):
#     print("\n ============================== \n Compare Strings \n ============================== \n")
#     matches = []
#     for kw in resume_keywords:
#         for cv_line in sanitised_split:
#             found = cv_line.find(kw)
#             if found != -1:
#                 print(kw, " ", "Match: ", cv_line)
#                 matches.append(cv_line)
#                 return matches
#
#
#
#
#
